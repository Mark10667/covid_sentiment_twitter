{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from twarc import Twarc\n",
    "from kafka import KafkaProducer\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently, having two topics: twitter & twittertry \n",
    "producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
    "# topic_name = \"twittertry\"\n",
    "topic_name = \"twitter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new csv file that only contains the tweet Id\n",
    "import pandas as pd\n",
    "df = pd.read_csv('corona_tweets/corona_tweets_470gcp.csv', delimiter=\",\")\n",
    "tweetId = df[df.columns[0]]\n",
    "tweetId.to_csv('tweetId.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many tweets \n",
    "import csv\n",
    "file = open(\"tweetId.csv\")\n",
    "reader = csv.reader(file)\n",
    "lines= len(list(reader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using kafka \n",
    "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "count = 0\n",
    "state_count = 0\n",
    "# hydrate is a generator function \n",
    "for tweet in t.hydrate(open('tweetId.csv')):\n",
    "\n",
    "    t = {'text': tweet['full_text'], \n",
    "     'user_location': tweet['user']['location']\n",
    "     }\n",
    "#     t = {'text': tweet['full_text'], \n",
    "#          'user_location': tweet['user']['location'], \n",
    "#          'tweet_place': tweet['place']}\n",
    "# geo location test \n",
    "#     test = {\n",
    "#         'user_location': tweet['user']['location'], \n",
    "#          'tweet_place': tweet['place'],\n",
    "#         'coordinates': tweet['coordinates']\n",
    "#     }\n",
    "#     if loc_filter(t['user_location']) != None:\n",
    "#         print(loc_filter(t['user_location']))\n",
    "#         print(t['text'])\n",
    "#         state_count += 1\n",
    "#     if test['coordinates'] != None:\n",
    "#         state_count += 1\n",
    "#         print(test['coordinates'])\n",
    "    count +=1 \n",
    "    print(count)\n",
    "# Producer: produce json strings and send out \n",
    "    producer.send(topic_name, json.dumps(t).encode('utf-8'))\n",
    "    if count >= 100:\n",
    "#         print(state_count)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without using kafka\n",
    "\n",
    "from csv import DictWriter\n",
    "headersCSV = ['text','location']  \n",
    "\n",
    "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "count = 0\n",
    "state_count = 0\n",
    "# hydrate is a generator function \n",
    "with open('geo_tweet_469.csv', 'w', newline='') as f_object:\n",
    "\n",
    "    dictwriter_object = DictWriter(f_object, fieldnames=headersCSV)\n",
    "\n",
    "    for tweet in t.hydrate(open('tweetId.csv')):\n",
    "\n",
    "        count +=1 \n",
    "        print(count)\n",
    "        if loc_filter(tweet['user']['location']) != None:\n",
    "            t = {\n",
    "                'text': tweet['full_text'],\n",
    "                'location': loc_filter(tweet['user']['location'])\n",
    "            }\n",
    "            print(t)\n",
    "\n",
    "            dictwriter_object.writerow(t)\n",
    "        if count >= 100000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read us cities csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('uscities.csv', delimiter=\",\")\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"city\"].head(5)\n",
    "df.loc[df['city'] == 'Melbourne']\n",
    "# find the corresponding row \n",
    "df.loc[df['state_id'] == 'CA']\n",
    "# find if a value is in a column \n",
    "if(df['state_id'].str.contains('CA').any()):\n",
    "    print(\"true\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state_name'].apply(lambda state : state.upper()=='NEW YORK').any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User location filter \n",
    "# By testing with big enough samples:\n",
    "# Aronud 8% of tweets have infomation of the user's state\n",
    "# Less than 0.5% of the tweets contain information like tweet's coordinates or user's place\n",
    "# Therefore, for now, we focus on the states information of the tweets \n",
    "\n",
    "def loc_filter(loc):\n",
    "    if ',' in loc:\n",
    "        s1 = loc.split(',')[0].strip().upper()\n",
    "        s2 = loc.split(',')[1].strip().upper()\n",
    "#         check if part before ',' is CA for instance \n",
    "        if(df['state_id'].apply(lambda state_id : state_id==s1).any()):\n",
    "            return(s1)\n",
    "#         check if part after ',' is CA for instance \n",
    "        elif(df['state_id'].apply(lambda state_id : state_id==s2).any()):\n",
    "            return(s2)\n",
    "#         check if part before ',' is CALIFORNIA for instance \n",
    "        elif(df['state_name'].apply(lambda state_name : state_name.upper()==s1).any()):\n",
    "            return(s1)\n",
    "#         check if part after ',' is CALIFORNIA for instance \n",
    "        elif(df['state_name'].apply(lambda state_name : state_name.upper()==s2).any()):\n",
    "            return(s2)\n",
    "        \n",
    "loc_filter('xxx, VA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "# count = 0\n",
    "# # hydrate is a generator function \n",
    "# for tweetId in open('corona_tweets_441.csv'):\n",
    "# #     print(tweet['full_text'])\n",
    "# #     print(\"User location: \", tweet['user']['location'])\n",
    "# #     print(\"Tweet place:\", tweet['place'])\n",
    "#     tweetId = tweetId.rpartition(',')[0]\n",
    "#     tweet = t.hydrate(tweetId)\n",
    "#     print(list(tweet))\n",
    "# #     info = {'text': tweet['full_text'], \n",
    "# #          'user_location': tweet['user']['location'], \n",
    "# #          'tweet_place': tweet['place']}\n",
    "#     print(count)\n",
    "#     count +=1 \n",
    "# #     print(tweetId.rpartition(',')[0])\n",
    "# # Producer: produce json strings and send out \n",
    "# #     producer.send(topic_name, json.dumps(t).encode('utf-8'))\n",
    "#     if count >= 500:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
